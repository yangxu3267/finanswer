#!/usr/bin/env python3
"""
åŸºäºç”¨æˆ·åé¦ˆçš„æ¨¡å‹é‡è®­ç»ƒè„šæœ¬
åˆ©ç”¨æ”¶é›†çš„ç”¨æˆ·åé¦ˆæ•°æ®æ¥æ”¹è¿› FinBERT æ¨¡å‹
"""

import json
import os
import numpy as np
import tensorflow as tf
from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification, TrainingArguments, Trainer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd
from datetime import datetime

class FeedbackBasedRetrainer:
    def __init__(self, model_path="../models/finbert", feedback_dir="../feedback_data"):
        self.model_path = model_path
        self.feedback_dir = feedback_dir
        self.tokenizer = None
        self.model = None
        self.feedback_data = []
        
    def load_model_and_tokenizer(self):
        """åŠ è½½ç°æœ‰æ¨¡å‹å’Œåˆ†è¯å™¨"""
        print("ğŸ”„ åŠ è½½ç°æœ‰æ¨¡å‹å’Œåˆ†è¯å™¨...")
        self.tokenizer = DistilBertTokenizer.from_pretrained(self.model_path)
        self.model = TFDistilBertForSequenceClassification.from_pretrained(self.model_path)
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def load_feedback_data(self):
        """åŠ è½½ç”¨æˆ·åé¦ˆæ•°æ®"""
        print("ğŸ“Š åŠ è½½ç”¨æˆ·åé¦ˆæ•°æ®...")
        
        if not os.path.exists(self.feedback_dir):
            print(f"âŒ åé¦ˆæ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.feedback_dir}")
            return False
            
        # åŠ è½½æ‰€æœ‰åé¦ˆæ–‡ä»¶
        for filename in os.listdir(self.feedback_dir):
            if filename.endswith('.json') and filename.startswith('feedback_'):
                filepath = os.path.join(self.feedback_dir, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        self.feedback_data.append(data)
                except Exception as e:
                    print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶ {filename}: {e}")
        
        print(f"ğŸ“ˆ åŠ è½½äº† {len(self.feedback_data)} æ¡åé¦ˆæ•°æ®")
        return len(self.feedback_data) > 0
    
    def prepare_training_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸ”§ å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        training_data = []
        
        for feedback in self.feedback_data:
            text = feedback.get('text', '').strip()
            if not text or len(text) < 10:  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬
                continue
                
            predicted_sentiment = feedback.get('predicted_sentiment')
            user_feedback = feedback.get('user_feedback')
            confidence = feedback.get('predicted_confidence', 0)
            
            # åªä½¿ç”¨ç”¨æˆ·åé¦ˆä¸º"inaccurate"çš„æ•°æ®è¿›è¡Œé‡è®­ç»ƒ
            if user_feedback == 'inaccurate':
                # è¿™é‡Œéœ€è¦ç”¨æˆ·æä¾›æ­£ç¡®çš„æ ‡ç­¾
                # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦äººå·¥æ ‡æ³¨æˆ–ä½¿ç”¨å…¶ä»–æ–¹æ³•
                # æš‚æ—¶è·³è¿‡è¿™äº›æ ·æœ¬
                continue
            
            # ä½¿ç”¨ç”¨æˆ·åé¦ˆä¸º"accurate"çš„æ•°æ®ä½œä¸ºæ­£æ ·æœ¬
            if user_feedback == 'accurate':
                # å°†é¢„æµ‹ç»“æœä½œä¸ºè®­ç»ƒæ ‡ç­¾
                label_map = {
                    'LABEL_0': 0,  # Negative
                    'LABEL_1': 1,  # Neutral
                    'LABEL_2': 2   # Positive
                }
                
                if predicted_sentiment in label_map:
                    training_data.append({
                        'text': text,
                        'label': label_map[predicted_sentiment],
                        'confidence': confidence
                    })
        
        print(f"ğŸ“š å‡†å¤‡äº† {len(training_data)} æ¡è®­ç»ƒæ•°æ®")
        return training_data
    
    def create_dataset(self, training_data):
        """åˆ›å»º TensorFlow æ•°æ®é›†"""
        if not training_data:
            print("âŒ æ²¡æœ‰è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®")
            return None, None
            
        texts = [item['text'] for item in training_data]
        labels = [item['label'] for item in training_data]
        
        # åˆ†è¯
        encodings = self.tokenizer(
            texts,
            truncation=True,
            padding=True,
            max_length=512,
            return_tensors="tf"
        )
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = tf.data.Dataset.from_tensor_slices((
            {
                'input_ids': encodings['input_ids'],
                'attention_mask': encodings['attention_mask']
            },
            labels
        ))
        
        # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
        total_size = len(training_data)
        train_size = int(0.8 * total_size)
        
        train_dataset = dataset.take(train_size)
        val_dataset = dataset.skip(train_size)
        
        print(f"ğŸ“Š è®­ç»ƒé›†: {train_size} æ ·æœ¬")
        print(f"ğŸ“Š éªŒè¯é›†: {total_size - train_size} æ ·æœ¬")
        
        return train_dataset, val_dataset
    
    def retrain_model(self, train_dataset, val_dataset):
        """é‡è®­ç»ƒæ¨¡å‹"""
        if not train_dataset or not val_dataset:
            print("âŒ æ— æ³•é‡è®­ç»ƒï¼šæ•°æ®é›†ä¸ºç©º")
            return False
            
        print("ğŸš€ å¼€å§‹æ¨¡å‹é‡è®­ç»ƒ...")
        
        # è®¾ç½®è®­ç»ƒå‚æ•°
        training_args = TrainingArguments(
            output_dir="./retrained_model",
            num_train_epochs=3,
            per_device_train_batch_size=8,
            per_device_eval_batch_size=8,
            warmup_steps=100,
            weight_decay=0.01,
            logging_dir="./logs",
            logging_steps=10,
            evaluation_strategy="steps",
            eval_steps=50,
            save_steps=100,
            load_best_model_at_end=True,
            metric_for_best_model="accuracy"
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            tokenizer=self.tokenizer
        )
        
        # å¼€å§‹è®­ç»ƒ
        try:
            trainer.train()
            print("âœ… æ¨¡å‹é‡è®­ç»ƒå®Œæˆ")
            return True
        except Exception as e:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def save_retrained_model(self):
        """ä¿å­˜é‡è®­ç»ƒåçš„æ¨¡å‹"""
        output_dir = f"./retrained_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        print(f"ğŸ’¾ ä¿å­˜é‡è®­ç»ƒæ¨¡å‹åˆ°: {output_dir}")
        
        try:
            self.model.save_pretrained(output_dir)
            self.tokenizer.save_pretrained(output_dir)
            print("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ")
            return output_dir
        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
            return None
    
    def evaluate_model(self, test_data=None):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        print("ğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
        
        if test_data is None:
            # ä½¿ç”¨éƒ¨åˆ†åé¦ˆæ•°æ®ä½œä¸ºæµ‹è¯•é›†
            test_data = self.feedback_data[-min(50, len(self.feedback_data)):]
        
        if not test_data:
            print("âŒ æ²¡æœ‰æµ‹è¯•æ•°æ®")
            return
        
        correct = 0
        total = 0
        
        for feedback in test_data:
            text = feedback.get('text', '').strip()
            if not text:
                continue
                
            # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
            inputs = self.tokenizer(
                text,
                truncation=True,
                padding=True,
                max_length=512,
                return_tensors="tf"
            )
            
            outputs = self.model(inputs)
            predictions = tf.nn.softmax(outputs.logits, axis=-1)
            predicted_label = tf.argmax(predictions, axis=-1).numpy()[0]
            
            # æ£€æŸ¥é¢„æµ‹æ˜¯å¦æ­£ç¡®ï¼ˆåŸºäºç”¨æˆ·åé¦ˆï¼‰
            user_feedback = feedback.get('user_feedback')
            if user_feedback == 'accurate':
                correct += 1
            total += 1
        
        if total > 0:
            accuracy = correct / total
            print(f"ğŸ“ˆ æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.2%} ({correct}/{total})")
        else:
            print("âŒ æ— æ³•è®¡ç®—å‡†ç¡®ç‡")
    
    def generate_retraining_report(self, training_data, output_dir):
        """ç”Ÿæˆé‡è®­ç»ƒæŠ¥å‘Š"""
        report = {
            "retraining_date": datetime.now().isoformat(),
            "original_model_path": self.model_path,
            "retrained_model_path": output_dir,
            "total_feedback_data": len(self.feedback_data),
            "training_samples": len(training_data),
            "feedback_accuracy": self._calculate_feedback_accuracy(),
            "model_improvements": self._suggest_improvements()
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"{output_dir}/retraining_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ é‡è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        return report
    
    def _calculate_feedback_accuracy(self):
        """è®¡ç®—åé¦ˆæ•°æ®çš„å‡†ç¡®ç‡"""
        if not self.feedback_data:
            return 0.0
            
        accurate = sum(1 for f in self.feedback_data if f.get('user_feedback') == 'accurate')
        return accurate / len(self.feedback_data)
    
    def _suggest_improvements(self):
        """å»ºè®®æ”¹è¿›æªæ–½"""
        suggestions = []
        
        # åˆ†æåé¦ˆæ•°æ®
        high_conf_errors = [
            f for f in self.feedback_data 
            if f.get('user_feedback') == 'inaccurate' and f.get('predicted_confidence', 0) > 0.8
        ]
        
        if high_conf_errors:
            suggestions.append(f"å‘ç° {len(high_conf_errors)} ä¸ªé«˜ç½®ä¿¡åº¦é”™è¯¯ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨")
        
        # åˆ†ææƒ…æ„Ÿåˆ†å¸ƒ
        sentiment_counts = {}
        for f in self.feedback_data:
            sentiment = f.get('predicted_sentiment')
            sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + 1
        
        if sentiment_counts:
            max_count = max(sentiment_counts.values())
            min_count = min(sentiment_counts.values())
            if max_count > min_count * 2:
                suggestions.append("æƒ…æ„Ÿåˆ†å¸ƒä¸å‡è¡¡ï¼Œå»ºè®®å¹³è¡¡è®­ç»ƒæ•°æ®")
        
        return suggestions

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– FinKnows æ¨¡å‹é‡è®­ç»ƒå·¥å…·")
    print("=" * 50)
    
    retrainer = FeedbackBasedRetrainer()
    
    # åŠ è½½æ¨¡å‹
    retrainer.load_model_and_tokenizer()
    
    # åŠ è½½åé¦ˆæ•°æ®
    if not retrainer.load_feedback_data():
        print("âŒ æ— æ³•åŠ è½½åé¦ˆæ•°æ®ï¼Œé€€å‡º")
        return
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    training_data = retrainer.prepare_training_data()
    if not training_data:
        print("âŒ æ²¡æœ‰è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®ï¼Œé€€å‡º")
        return
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset, val_dataset = retrainer.create_dataset(training_data)
    if not train_dataset or not val_dataset:
        print("âŒ æ— æ³•åˆ›å»ºæ•°æ®é›†ï¼Œé€€å‡º")
        return
    
    # é‡è®­ç»ƒæ¨¡å‹
    if retrainer.retrain_model(train_dataset, val_dataset):
        # ä¿å­˜æ¨¡å‹
        output_dir = retrainer.save_retrained_model()
        if output_dir:
            # è¯„ä¼°æ¨¡å‹
            retrainer.evaluate_model()
            
            # ç”ŸæˆæŠ¥å‘Š
            retrainer.generate_retraining_report(training_data, output_dir)
            
            print(f"\nğŸ‰ æ¨¡å‹é‡è®­ç»ƒå®Œæˆï¼")
            print(f"ğŸ“ æ–°æ¨¡å‹ä¿å­˜åœ¨: {output_dir}")
            print(f"ğŸ“Š ä½¿ç”¨äº† {len(training_data)} æ¡è®­ç»ƒæ•°æ®")
        else:
            print("âŒ æ¨¡å‹ä¿å­˜å¤±è´¥")
    else:
        print("âŒ æ¨¡å‹é‡è®­ç»ƒå¤±è´¥")

if __name__ == "__main__":
    main() 