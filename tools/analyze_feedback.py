#!/usr/bin/env python3
"""
åé¦ˆæ•°æ®åˆ†æè„šæœ¬
ç”¨äºåˆ†æç”¨æˆ·åé¦ˆæ•°æ®ï¼Œè¯†åˆ«æ¨¡å‹æ”¹è¿›æœºä¼š
"""

import json
import os
import pandas as pd
from collections import Counter
import re
from datetime import datetime, timedelta

class FeedbackAnalyzer:
    def __init__(self, feedback_dir="feedback_data"):
        self.feedback_dir = feedback_dir
        self.feedback_files = []
        self.feedback_data = []
        
    def load_feedback_data(self):
        """åŠ è½½æ‰€æœ‰åé¦ˆæ•°æ®"""
        if not os.path.exists(self.feedback_dir):
            print(f"âŒ åé¦ˆæ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.feedback_dir}")
            return
            
        # è·å–æ‰€æœ‰åé¦ˆæ–‡ä»¶
        for filename in os.listdir(self.feedback_dir):
            if filename.endswith('.json') and filename.startswith('feedback_'):
                filepath = os.path.join(self.feedback_dir, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        data['filename'] = filename
                        self.feedback_data.append(data)
                except Exception as e:
                    print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶ {filename}: {e}")
        
        print(f"ğŸ“Š åŠ è½½äº† {len(self.feedback_data)} æ¡åé¦ˆæ•°æ®")
    
    def generate_report(self):
        """ç”Ÿæˆåé¦ˆåˆ†ææŠ¥å‘Š"""
        if not self.feedback_data:
            print("âŒ æ²¡æœ‰åé¦ˆæ•°æ®å¯åˆ†æ")
            return
            
        print("\n" + "="*60)
        print("ğŸ“ˆ FinKnows åé¦ˆæ•°æ®åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # åŸºç¡€ç»Ÿè®¡
        self._basic_statistics()
        
        # é”™è¯¯æ¨¡å¼åˆ†æ
        self._error_pattern_analysis()
        
        # é«˜ç½®ä¿¡åº¦é”™è¯¯åˆ†æ
        self._high_confidence_error_analysis()
        
        # æƒ…æ„Ÿåˆ†å¸ƒåˆ†æ
        self._sentiment_distribution_analysis()
        
        # æ–‡æœ¬ç‰¹å¾åˆ†æ
        self._text_feature_analysis()
        
        # æ¨¡å‹æ”¹è¿›å»ºè®®
        self._model_improvement_suggestions()
    
    def _basic_statistics(self):
        """åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š åŸºç¡€ç»Ÿè®¡ä¿¡æ¯:")
        print("-" * 30)
        
        total = len(self.feedback_data)
        accurate = sum(1 for f in self.feedback_data if f.get('user_feedback') == 'accurate')
        inaccurate = total - accurate
        accuracy_rate = accurate / total if total > 0 else 0
        
        print(f"æ€»åé¦ˆæ•°: {total}")
        print(f"å‡†ç¡®é¢„æµ‹: {accurate}")
        print(f"é”™è¯¯é¢„æµ‹: {inaccurate}")
        print(f"å‡†ç¡®ç‡: {accuracy_rate:.2%}")
        
        # æ—¶é—´åˆ†å¸ƒ
        if self.feedback_data:
            timestamps = [f.get('timestamp') for f in self.feedback_data if f.get('timestamp')]
            if timestamps:
                try:
                    dates = [datetime.fromisoformat(ts.replace('Z', '+00:00')) for ts in timestamps]
                    date_range = f"{min(dates).strftime('%Y-%m-%d')} åˆ° {max(dates).strftime('%Y-%m-%d')}"
                    print(f"æ•°æ®æ—¶é—´èŒƒå›´: {date_range}")
                except:
                    pass
    
    def _error_pattern_analysis(self):
        """é”™è¯¯æ¨¡å¼åˆ†æ"""
        print("\nğŸš¨ é”™è¯¯æ¨¡å¼åˆ†æ:")
        print("-" * 30)
        
        errors = [f for f in self.feedback_data if f.get('user_feedback') == 'inaccurate']
        if not errors:
            print("âœ… æ²¡æœ‰å‘ç°é”™è¯¯é¢„æµ‹")
            return
            
        # æŒ‰æƒ…æ„Ÿæ ‡ç­¾åˆ†æé”™è¯¯
        error_by_sentiment = Counter(f.get('predicted_sentiment') for f in errors)
        print("é”™è¯¯é¢„æµ‹çš„æƒ…æ„Ÿåˆ†å¸ƒ:")
        for sentiment, count in error_by_sentiment.most_common():
            sentiment_name = {
                'LABEL_0': 'Negative',
                'LABEL_1': 'Neutral', 
                'LABEL_2': 'Positive'
            }.get(sentiment, sentiment)
            print(f"  {sentiment_name}: {count} æ¬¡")
    
    def _high_confidence_error_analysis(self):
        """é«˜ç½®ä¿¡åº¦é”™è¯¯åˆ†æ"""
        print("\nâš ï¸ é«˜ç½®ä¿¡åº¦é”™è¯¯åˆ†æ:")
        print("-" * 30)
        
        high_conf_errors = [
            f for f in self.feedback_data 
            if f.get('user_feedback') == 'inaccurate' and f.get('predicted_confidence', 0) > 0.8
        ]
        
        if not high_conf_errors:
            print("âœ… æ²¡æœ‰é«˜ç½®ä¿¡åº¦é”™è¯¯")
            return
            
        print(f"å‘ç° {len(high_conf_errors)} ä¸ªé«˜ç½®ä¿¡åº¦é”™è¯¯:")
        
        for error in high_conf_errors[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            sentiment = error.get('predicted_sentiment', 'Unknown')
            confidence = error.get('predicted_confidence', 0)
            text_preview = error.get('text', '')[:100] + '...' if len(error.get('text', '')) > 100 else error.get('text', '')
            
            print(f"  - {sentiment} (ç½®ä¿¡åº¦: {confidence:.2%}): {text_preview}")
    
    def _sentiment_distribution_analysis(self):
        """æƒ…æ„Ÿåˆ†å¸ƒåˆ†æ"""
        print("\nğŸ“Š æƒ…æ„Ÿåˆ†å¸ƒåˆ†æ:")
        print("-" * 30)
        
        sentiment_counts = Counter(f.get('predicted_sentiment') for f in self.feedback_data)
        total = len(self.feedback_data)
        
        sentiment_names = {
            'LABEL_0': 'Negative',
            'LABEL_1': 'Neutral',
            'LABEL_2': 'Positive'
        }
        
        for sentiment, count in sentiment_counts.most_common():
            name = sentiment_names.get(sentiment, sentiment)
            percentage = count / total * 100
            print(f"{name}: {count} æ¬¡ ({percentage:.1f}%)")
    
    def _text_feature_analysis(self):
        """æ–‡æœ¬ç‰¹å¾åˆ†æ"""
        print("\nğŸ” æ–‡æœ¬ç‰¹å¾åˆ†æ:")
        print("-" * 30)
        
        # åˆ†æé”™è¯¯é¢„æµ‹çš„æ–‡æœ¬ç‰¹å¾
        errors = [f for f in self.feedback_data if f.get('user_feedback') == 'inaccurate']
        if not errors:
            return
            
        # æå–å¸¸è§è¯æ±‡
        all_error_texts = ' '.join([f.get('text', '').lower() for f in errors])
        words = re.findall(r'\b\w+\b', all_error_texts)
        
        # è¿‡æ»¤å¸¸è§è¯æ±‡
        common_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'can', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them'}
        filtered_words = [word for word in words if word not in common_words and len(word) > 3]
        
        word_counts = Counter(filtered_words)
        print("é”™è¯¯é¢„æµ‹ä¸­æœ€å¸¸è§çš„è¯æ±‡:")
        for word, count in word_counts.most_common(10):
            print(f"  {word}: {count} æ¬¡")
    
    def _model_improvement_suggestions(self):
        """æ¨¡å‹æ”¹è¿›å»ºè®®"""
        print("\nğŸ’¡ æ¨¡å‹æ”¹è¿›å»ºè®®:")
        print("-" * 30)
        
        suggestions = []
        
        # åˆ†æé”™è¯¯ç‡
        total = len(self.feedback_data)
        errors = len([f for f in self.feedback_data if f.get('user_feedback') == 'inaccurate'])
        error_rate = errors / total if total > 0 else 0
        
        if error_rate > 0.3:
            suggestions.append("ğŸ”´ é”™è¯¯ç‡è¾ƒé«˜ (>30%)ï¼Œå»ºè®®é‡æ–°è®­ç»ƒæ¨¡å‹æˆ–å¢åŠ è®­ç»ƒæ•°æ®")
        elif error_rate > 0.2:
            suggestions.append("ğŸŸ¡ é”™è¯¯ç‡ä¸­ç­‰ (20-30%)ï¼Œå»ºè®®ä¼˜åŒ–æ¨¡å‹å‚æ•°æˆ–å¢åŠ ç‰¹å®šé¢†åŸŸæ•°æ®")
        else:
            suggestions.append("ğŸŸ¢ é”™è¯¯ç‡è¾ƒä½ (<20%)ï¼Œæ¨¡å‹è¡¨ç°è‰¯å¥½")
        
        # åˆ†æé«˜ç½®ä¿¡åº¦é”™è¯¯
        high_conf_errors = len([
            f for f in self.feedback_data 
            if f.get('user_feedback') == 'inaccurate' and f.get('predicted_confidence', 0) > 0.8
        ])
        
        if high_conf_errors > 0:
            suggestions.append(f"âš ï¸ å‘ç° {high_conf_errors} ä¸ªé«˜ç½®ä¿¡åº¦é”™è¯¯ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨è¿™äº›æ ·æœ¬")
        
        # åˆ†ææƒ…æ„Ÿåˆ†å¸ƒåå·®
        sentiment_counts = Counter(f.get('predicted_sentiment') for f in self.feedback_data)
        if sentiment_counts:
            max_count = max(sentiment_counts.values())
            min_count = min(sentiment_counts.values())
            if max_count > min_count * 3:
                suggestions.append("ğŸ“Š æƒ…æ„Ÿåˆ†å¸ƒä¸å‡è¡¡ï¼Œå»ºè®®å¹³è¡¡è®­ç»ƒæ•°æ®")
        
        # è¾“å‡ºå»ºè®®
        for suggestion in suggestions:
            print(suggestion)
        
        if not suggestions:
            print("âœ… æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œæš‚æ— æ”¹è¿›å»ºè®®")
    
    def export_analysis_report(self, filename="feedback_analysis_report.txt"):
        """å¯¼å‡ºåˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶"""
        import sys
        from io import StringIO
        
        # é‡å®šå‘è¾“å‡º
        old_stdout = sys.stdout
        sys.stdout = StringIO()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        # è·å–è¾“å‡ºå†…å®¹
        report_content = sys.stdout.getvalue()
        sys.stdout = old_stdout
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = FeedbackAnalyzer()
    analyzer.load_feedback_data()
    analyzer.generate_report()
    
    # è¯¢é—®æ˜¯å¦å¯¼å‡ºæŠ¥å‘Š
    try:
        export = input("\næ˜¯å¦å¯¼å‡ºåˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶? (y/n): ").lower().strip()
        if export == 'y':
            analyzer.export_analysis_report()
    except:
        pass

if __name__ == "__main__":
    main() 